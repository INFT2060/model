{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c9bc0f-4b26-450f-b133-c147514d8ee4",
   "metadata": {},
   "source": [
    "## This just needs the images from the 'df_train_preprocessed_clip_labels.csv' in 'path' column to be present in the method stated "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeedd20-6f78-42a1-8652-35147987e027",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea916e3-e39a-4009-9cf0-8289b2867bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ftfy regex tqdm\n",
    "#pip install git+https://github.com/openai/CLIP.git\n",
    "#pip install scikit-learn pandas matplotlib tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223896b8-52c3-4f56-b245-56441d776e36",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c5c37b-56f3-4c83-8aca-2402aebf508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3189141-43cb-4d56-9525-5de5e62ed8ec",
   "metadata": {},
   "source": [
    "### Load and Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3885d303-f7f1-4615-b0b0-623ae9a98955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your CSV file\n",
    "df = pd.read_csv(\"df_train_preprocessed_clip_labels.csv\") \n",
    "\n",
    "# Drop missing paths or captions\n",
    "df = df.dropna(subset=['path', 'caption_concise'])\n",
    "\n",
    "# Train-test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af18a5f-44ca-4abb-b8bc-0e4a4dbc0a4e",
   "metadata": {},
   "source": [
    "### Load CLIP and Define Embedding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7765a7c-2f63-4c50-9fa0-9be56bd33c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "def get_clip_embeddings(dataframe):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, row in tqdm(dataframe.iterrows(), total=len(dataframe)):\n",
    "        try:\n",
    "            image = preprocess(Image.open(row['path']).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                image_features = model.encode_image(image)\n",
    "                image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "            features.append(image_features.cpu().numpy())\n",
    "            labels.append(row['caption_concise'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error on {row['path']}: {e}\")\n",
    "    \n",
    "    return np.vstack(features), labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34b6ac9-237f-443d-aa40-11ac6b4e9630",
   "metadata": {},
   "source": [
    "### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd89e1f-dab8-4b83-9474-d72933fe9168",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, y_train_text = get_clip_embeddings(train_df)\n",
    "X_test, y_test_text = get_clip_embeddings(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc42ff6-63a7-47d0-9296-0b33a3a7f49d",
   "metadata": {},
   "source": [
    "### Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45a743c-9803-4116-8fe8-5269755aab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train_text)\n",
    "y_test = le.transform(y_test_text)\n",
    "\n",
    "class_names = le.classes_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b4d0e1-18ff-4c02-a361-33aaed664f77",
   "metadata": {},
   "source": [
    "### Create TensorFlow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3fcac4-de38-48c6-b79c-7324da10f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(500).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a39a3d-6b61-4779-99dc-b9775e82e021",
   "metadata": {},
   "source": [
    "### Build and Compile Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d044de92-90af-406c-94ee-8c6f6ef42958",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(512,)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "model_tf.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50cf21a-1e15-4b60-8445-901e0544b4fd",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c8aa25-d894-4037-a794-caff143d4c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_tf.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820dd1a1-f1f3-4517-a5da-5e0fd755ce2c",
   "metadata": {},
   "source": [
    "### Plot Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ba16e-ef02-4aad-a05a-71ce52a06b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Test Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ebac37-b35a-4aad-9814-2e66e01a3091",
   "metadata": {},
   "source": [
    "### Repeat & Average Multiple Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca47fef-bf8d-4268-b3b8-8554edd492f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "\n",
    "for seed in range(5):\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "    \n",
    "    X_train, y_train_text = get_clip_embeddings(train_df)\n",
    "    X_test, y_test_text = get_clip_embeddings(test_df)\n",
    "    \n",
    "    y_train = le.fit_transform(y_train_text)\n",
    "    y_test = le.transform(y_test_text)\n",
    "    \n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(500).batch(32)\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)\n",
    "    \n",
    "    model_tf = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(512,)),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(len(class_names), activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model_tf.compile(optimizer='adam',\n",
    "                     loss='sparse_categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "    \n",
    "    history = model_tf.fit(train_ds, validation_data=test_ds, epochs=10, verbose=0)\n",
    "    \n",
    "    acc = history.history['val_accuracy'][-1]\n",
    "    accuracies.append(acc)\n",
    "    print(f\"Run {seed+1} Accuracy: {acc:.4f}\")\n",
    "\n",
    "print(f\"\\nAverage Accuracy: {np.mean(accuracies):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
