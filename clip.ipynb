{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a16553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this the first time installing PyTorch and other dependencies\n",
    "# conda install --yes -c pytorch pytorch=1.7.1 torchvision cudatoolkit=11.0\n",
    "# pip install ftfy regex tqdm\n",
    "# pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce04715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a30bce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top predictions:\n",
      "\n",
      "           snake: 65.31%\n",
      "          turtle: 12.29%\n",
      "    sweet_pepper: 3.83%\n",
      "          lizard: 1.88%\n",
      "       crocodile: 1.75%\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR100\n",
    "\n",
    "# Load the model\n",
    "if (torch.cuda.is_available()):\n",
    "    device = torch.device(\"cuda\")\n",
    "elif (torch.backends.mps.is_available()):\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "\n",
    "# Download the dataset\n",
    "cifar100 = CIFAR100(root=os.path.expanduser(\"~/.cache\"), download=True, train=False)\n",
    "\n",
    "# Prepare the inputs\n",
    "image, class_id = cifar100[3637]\n",
    "image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in cifar100.classes]).to(device)\n",
    "\n",
    "# Calculate features\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image_input)\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "\n",
    "# Pick the top 5 most similar labels for the image\n",
    "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "values, indices = similarity[0].topk(5)\n",
    "\n",
    "# Print the result\n",
    "print(\"\\nTop predictions:\\n\")\n",
    "for value, index in zip(values, indices):\n",
    "    print(f\"{cifar100.classes[index]:>16s}: {100 * value.item():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594672ae",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cac4e0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset/df_train_preprocessed_clip_labels.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a robust preprocessing pipeline for chest X-ray reports into CLIP-friendly captions\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dataset/df_train_partial_10000.csv\")\n",
    "\n",
    "# -------------------- helper regexes --------------------\n",
    "\n",
    "SENTENCE_SPLIT = re.compile(r\"(?<=[\\.\\?\\!])\\s+\")\n",
    "NON_CHEST_TERMS = re.compile(r\"\\b(bowel gas|abdomen(al)?|pelvis|shoulder|humerus|knee|hip)\\b\", re.I)\n",
    "\n",
    "# Phrases to drop entirely (cross-modal, temporal, recommendations, uncertainty boilerplate)\n",
    "DROP_PATTERNS = [\n",
    "    r\"\\bcompared to\\b.*\",                     # comparisons\n",
    "    r\"\\bunchanged since\\b.*\",\n",
    "    r\"\\bsince\\s+\\d{2,4}\\b.*\",\n",
    "    r\"\\bprior\\b.*\",                           # generic \"prior\" sentence\n",
    "    r\"\\bprevious\\b.*\",\n",
    "    r\"\\bbetter (seen|demonstrated) on\\b.*\",\n",
    "    r\"\\b(read in conjunction|correlate clinically|clinical correlation)\\b.*\",\n",
    "    r\"\\bif (clinically|otherwise) indicated\\b.*\",\n",
    "    r\"\\bfollow[- ]?up\\b.*\",\n",
    "    r\"\\bmanagement recommendations?\\b.*\",\n",
    "    r\"\\bCT\\b.*\",                              # cross-modal references\n",
    "    r\"\\bMRI\\b.*\",\n",
    "    r\"\\bultrasound\\b.*\",\n",
    "    r\"\\bechocardiogram?\\b.*\",\n",
    "    r\"\\bPET[- ]?CT\\b.*\",\n",
    "    r\"\\bfluoroscopy\\b.*\",\n",
    "    r\"___\",                                   # placeholder blanks\n",
    "    r\"\\bportable AP\\b.*\",                     # technical headers\n",
    "    r\"\\bAP chest\\b.*\",\n",
    "    r\"\\bPA and lateral\\b.*\",\n",
    "]\n",
    "\n",
    "# Light rewrites / normalizations\n",
    "REWRITES = [\n",
    "    (r\"\\bcardiac and mediastinal contours\\b\", \"cardiomediastinal contours\"),\n",
    "    (r\"\\bPort[\\-\\s]?A[\\-\\s]?Cath\\b\", \"Port-A-Cath\"),\n",
    "    (r\"\\bETT\\b\", \"endotracheal tube\"),\n",
    "    (r\"\\bNG[-\\s]?tube\\b|\\bnasogastric tube\\b\", \"nasogastric tube\"),\n",
    "    (r\"\\bPICC\\b\", \"PICC line\"),\n",
    "    (r\"\\bCVC\\b\", \"central venous catheter\"),\n",
    "    (r\"\\bchest[-\\s]?port\\b|\\bmediport\\b\", \"Port-A-Cath\"),\n",
    "    (r\"\\bcardiomediastinal silhouette\\b\", \"cardiomediastinal contours\"),\n",
    "    (r\"\\bhemi[-\\s]?thorax\\b\", \"hemithorax\"),\n",
    "    (r\"\\bno acute cardiopulmonary abnormality\\b\", \"no acute cardiopulmonary abnormality\"),\n",
    "]\n",
    "\n",
    "# Simple clinical finding extraction with negation detection\n",
    "FINDINGS = {\n",
    "    \"pleural_effusion\": r\"\\bpleural (?:fluid|effusions?)\\b|\\beffusion(s)?\\b\",\n",
    "    \"pneumothorax\": r\"\\bpneumothorax\\b\",\n",
    "    \"consolidation\": r\"\\bconsolidation(s)?\\b\",\n",
    "    \"atelectasis\": r\"\\batelectasis\\b|\\bplate (?:like|atelectatic)\\b\",\n",
    "    \"pulmonary_edema\": r\"\\b(edema|oedema)\\b\",\n",
    "    \"cardiomegaly\": r\"\\bcardiomegaly\\b|\\benlarged (cardiac|heart)\\b\",\n",
    "    \"pleural_thickening\": r\"\\bpleural thickening\\b\",\n",
    "    \"nodular_opacities\": r\"\\bnodular opacit(?:y|ies)\\b|\\bnodules?\\b\",\n",
    "    \"pacemaker\": r\"\\bpacemaker\\b|\\bICD\\b\",\n",
    "    \"endotracheal_tube\": r\"\\bendotracheal tube\\b\",\n",
    "    \"nasogastric_tube\": r\"\\bnasogastric tube\\b\",\n",
    "    \"picc_cvc\": r\"\\bPICC line\\b|\\bcentral venous catheter\\b|\\bcentral line\\b\",\n",
    "    \"port_a_cath\": r\"\\bPort-A-Cath\\b\",\n",
    "    \"cardiomediastinal_normal\": r\"\\bcardiomediastinal (?:contours|silhouette) (?:are )?normal\\b|\\bheart size (?:is )?normal\\b\",\n",
    "}\n",
    "\n",
    "NEGATION = r\"\\b(no|without|absent|free of|negative for)\\b\"\n",
    "\n",
    "def has_finding(text, pattern):\n",
    "    # positive if pattern exists and not negated within ~5 words before it\n",
    "    for m in re.finditer(pattern, text, flags=re.I):\n",
    "        start = max(0, m.start()-50)\n",
    "        window = text[start:m.start()]\n",
    "        if not re.search(NEGATION, window, flags=re.I):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_negated(text, pattern):\n",
    "    return bool(re.search(NEGATION + r\".{0,20}\" + pattern, text, flags=re.I))\n",
    "\n",
    "def clean_sentences(text):\n",
    "    # Normalize whitespace\n",
    "    t = re.sub(r\"\\s+\", \" \", text.strip())\n",
    "    # Split to sentences\n",
    "    sents = SENTENCE_SPLIT.split(t) if t else []\n",
    "    kept = []\n",
    "    for s in sents:\n",
    "        s0 = s.strip()\n",
    "        if not s0:\n",
    "            continue\n",
    "        # Drop non-chest sentences\n",
    "        if NON_CHEST_TERMS.search(s0):\n",
    "            continue\n",
    "        # Drop noisy patterns\n",
    "        if any(re.search(p, s0, flags=re.I) for p in DROP_PATTERNS):\n",
    "            continue\n",
    "        # Apply rewrites\n",
    "        for pat, rep in REWRITES:\n",
    "            s0 = re.sub(pat, rep, s0, flags=re.I)\n",
    "        kept.append(s0)\n",
    "    return kept\n",
    "\n",
    "def compress_to_caption(sents, max_tokens=70):\n",
    "    # Join and then trim by tokens\n",
    "    caption = \" \".join(sents)\n",
    "    tokens = caption.split()\n",
    "    if len(tokens) > max_tokens:\n",
    "        caption = \" \".join(tokens[:max_tokens]) + \".\"\n",
    "    return caption\n",
    "\n",
    "def concise_caption(sents, max_tokens=35):\n",
    "    # Prefer key finding sentences: devices, effusion, pneumothorax, consolidation, atelectasis, edema, cardiomediastinal\n",
    "    priority = []\n",
    "    others = []\n",
    "    key_patterns = [\n",
    "        r\"Port-A-Cath\", r\"pleural\", r\"pneumothorax\", r\"consolidation\", r\"atelectasis\",\n",
    "        r\"edema|oedema\", r\"cardiomediastinal\", r\"pacemaker\", r\"tube\", r\"line\", r\"nodule|nodular\"\n",
    "    ]\n",
    "    for s in sents:\n",
    "        if any(re.search(k, s, flags=re.I) for k in key_patterns):\n",
    "            priority.append(s)\n",
    "        else:\n",
    "            others.append(s)\n",
    "    ordered = priority + others\n",
    "    return compress_to_caption(ordered, max_tokens=max_tokens)\n",
    "\n",
    "def extract_tags(text):\n",
    "    tags = {}\n",
    "    for name, pat in FINDINGS.items():\n",
    "        present = has_finding(text, pat)\n",
    "        neg = is_negated(text, pat)\n",
    "        if present:\n",
    "            tags[name] = \"present\"\n",
    "        elif neg:\n",
    "            tags[name] = \"absent\"\n",
    "    return tags\n",
    "\n",
    "def preprocess_report(text):\n",
    "    sents = clean_sentences(text or \"\")\n",
    "    cap_long = compress_to_caption(sents, max_tokens=70)\n",
    "    cap_short = concise_caption(sents, max_tokens=35)\n",
    "    tags = extract_tags(\" \".join(sents))\n",
    "    return cap_long, cap_short, json.dumps(tags, ensure_ascii=False)\n",
    "\n",
    "# Apply to the dataset\n",
    "out = df.copy()\n",
    "cap_long_list = []\n",
    "cap_short_list = []\n",
    "tags_list = []\n",
    "\n",
    "for t in out[\"text\"].fillna(\"\").tolist():\n",
    "    long_c, short_c, tags = preprocess_report(t)\n",
    "    cap_long_list.append(long_c)\n",
    "    cap_short_list.append(short_c)\n",
    "    tags_list.append(tags)\n",
    "\n",
    "out[\"caption\"] = cap_long_list\n",
    "out[\"caption_concise\"] = cap_short_list\n",
    "out[\"tags_json\"] = tags_list\n",
    "\n",
    "# Save\n",
    "save_path = \"dataset/df_train_preprocessed_clip_labels.csv\"\n",
    "out.to_csv(save_path, index=False)\n",
    "\n",
    "# Show a small preview to the user\n",
    "preview = out[[\"id\", \"path\", \"caption\", \"caption_concise\", \"tags_json\"]].head(15)\n",
    "\n",
    "save_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77791bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
